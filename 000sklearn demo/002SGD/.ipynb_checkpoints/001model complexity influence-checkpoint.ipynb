{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__);\n",
    "\n",
    "import time\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.axes_grid1.parasite_axes import host_subplot\n",
    "from mpl_toolkits.axisartist.axislines import Axes\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle  #以一致的方式排列数组或稀疏矩阵\n",
    "from sklearn.metrics import mean_squared_error  #\n",
    "from sklearn.svm.classes import NuSVR\n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingRegressor\n",
    "from sklearn.linear_model.stochastic_gradient import SGDClassifier\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "\n",
    "    def generate_data(case,sparse=False):\n",
    "        bunch = None\n",
    "        if case == 'regression':\n",
    "            bunch = datasets.load_boston()\n",
    "        elif case == 'classification':\n",
    "            bunch = datasets.fetch_20newsgroups_vectorized(subset='all')\n",
    "        x,y = shuffle(bunch.data,bunch.target)\n",
    "        offset = int(x,shape[0]*0.8)\n",
    "        x_train,y_train = x[:offset],y[:offset]\n",
    "        x_test,y_test = x[offset:],y[offset:]\n",
    "        if sparse:\n",
    "            x_train = csr_matrix(x_train)\n",
    "            x_test = csr_matrix(x_test)\n",
    "        else:\n",
    "            x_train = np.array(x_train)\n",
    "            x_test = np.array(x_test)\n",
    "        y_test = np.array(y_test)\n",
    "        y_train = np.array(y_train)\n",
    "        data = {'x_train':x_train,'x_test':x_test,'y_train':y_train,'y_test':y_test}\n",
    "        return data\n",
    "\n",
    "\n",
    "    def benchmark_influence(conf):\n",
    "        prediction_times = []\n",
    "        prediction_powers = []\n",
    "        complexities =[]\n",
    "        for param_value in conf['changing_param_values']:\n",
    "            conf['tuned_params'][conf['changing_param']] = param_value\n",
    "            estimator = conf['estimator'](**conf['tuned_params'])\n",
    "            print(\"Benchmarking %s\" % estimator)\n",
    "            estimator.fit(conf['data']['x_train'],conf['data']['y_train'])\n",
    "            conf['postfit_hook'](estimator)\n",
    "            complexity = conf['complexity_computer'](estimator)\n",
    "            complexities.append(complexity)\n",
    "            start_time = time.time()\n",
    "        for _ in range(conf['n_samples']):\n",
    "            y_pred = estimator.predict(conf['data']['x_test'])\n",
    "        elapsed_time = (time.time() - start_time)/float(conf['n_samples'])\n",
    "        prediction_times.append(elapsed_time)\n",
    "        pred_score = conf['prediction_performance_computer'](conf['data']['y_test'],y_pred)\n",
    "        prediction_powers.append(pred_score)\n",
    "        print(\"Complexity:%d | %s:%.4f | Pred. Time:%fs\\n\"%(complexity,conf['prediction_performance_label'],pred_score,elapsed_time))\n",
    "        return prediction_powers,prediction_times,complexities\n",
    "    \n",
    "    def plot_influence(conf,mse_values,prediction_times,complexities):\n",
    "        plt.figure(figsize=(12,6))\n",
    "        host = host_subplot(111,axes_class=Axes)\n",
    "        plt.subplots_adjust(right=0.75)\n",
    "        par1 = host.twinx()\n",
    "        host.set_xlabel('Model Complexity(%s)' % conf['complexity_label'])\n",
    "        y1_label = conf['prediction_performance_label']\n",
    "        y2_label = \"Time(s)\"\n",
    "        host.set_ylabel(y1_label)\n",
    "        par1.set_ylabel(y2_label)\n",
    "        p1,=host.plot(complexities,mse_values,'b-',label=\"prediction error\")\n",
    "        p2,=par1.plot(complexities,prediction_times,'r-',label=\"latency\")\n",
    "        host.legend(loc='upper right')\n",
    "        host.axis[\"left\"].label.set_color(p1.get_color())\n",
    "        host.axis[\"right\"].label.set_color(p2.get_color())\n",
    "        plt.title('Influence of Model Complexity - %s' % conf['estimator']._name_)\n",
    "        plt.show()\n",
    "        \n",
    "    def _count_nonzero_coefficients(estimator):\n",
    "        a = estimator.coef_.toarray()\n",
    "        return np.count_nonzero(a)\n",
    "    \n",
    "    regression_data = generate_data('regression')\n",
    "    classification_data = generate_data('classification',sparse=True)\n",
    "    configurations = [\n",
    "        {'estimator':SGDClassifier,'tuned_params':{'penalty':'elasticnet','alpha':0.001,'loss':\n",
    "                                                  'modified_huber','fit_intercept':True},\n",
    "         'changing_param':'l1_ratio',\n",
    "         'changing_param_values':[0.25,0.5,0.75,0.9],\n",
    "         'complexity_label':'non_zero coefficients',\n",
    "         'complexity_computer':_count_nonzero_coefficients,\n",
    "         'prediction_performance_computer':hamming_loss,\n",
    "         'prediction_performance_label':'Hamming Loss (Misclassification Ratio)',\n",
    "         'postfit_hook':lambda x:x.sparsify(),\n",
    "         'data':classification_data,\n",
    "         'n_samples':30},\n",
    "         {'estimator':NuSVR,\n",
    "          'tuned_params':{'c':le3,'gamma':2 ** -15},\n",
    "          'changing_param':'nu',\n",
    "          'changing_param_values':[0.1,0.25,0.5,0.75,0.9],\n",
    "          'complexity_label':'n_support_vectors',\n",
    "          'complexity_computer':lambda x: len(x.support_vectors_),\n",
    "          'data':regression_data,\n",
    "          'postfit_hook':lambda x:x,\n",
    "          'prediction_performance_computer':mean_squared_error,\n",
    "          'perdiction_performance_label':'MSE',\n",
    "          'n_samples':30},\n",
    "         {'estimator':GradientBoostingRegressor,\n",
    "          'tuned_params':{'loss':'ls'},\n",
    "          'changing_param':'n_estimators',\n",
    "          'changing_param_values':[10,50,100,200,500],\n",
    "          'complexity_label':'n_trees',\n",
    "          'complexity_computer':lambda x: x.estimators,\n",
    "          'data':regression_data,\n",
    "          'postfit_hook':lambda x:x,\n",
    "          'prediction_performance_computer':mean_squared_error,\n",
    "          'perdiction_performance_label':'MSE',\n",
    "          'n_samples':30}\n",
    "    ]\n",
    "    for conf in configurations:\n",
    "        prediction_performances,prediction_times,complexities = benchmark_influence(conf)\n",
    "        plot_influence(conf,prediction_performances,prediction_times,complexxities)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
